## fine tuning 
Hello everyone and welcome back.

Let's talk about fine tuning now.


**So we already talked about large language models like GPT or Facebook Llama or Google Bard.And like I mentioned, they are trained on huge volumes of dataset which enables them to perform great on almost any question.I mean, you ask ChatGPT question on any generic topic and it will give you good answer.**

---

**So llms are generally pre-trained and very accurate.But all of this is general purpose training.If you are looking to generate information about a specific task or a specific data set from your organization,you will need to train the model on your particular data set.And that is where fine tuning comes into picture.**

---

## **So what is fine tuning?**

**It is like adjusting a pre-trained LM or what we call foundation model to do more specific task.**
---

## Why do we do it?

**We do it to achieve better results on a focused data set for example, a fine tuned on medical data set will give you better answers to your queries then a foundation or vanilla one.So that was the what and why part.**

---
## Let's talk about how how do we do fine tuning.

**So there are three ways to fine tune a model.And the first one is called as self-supervised fine tuning.**

## **self-supervised fine tuning**

***And what it means is you give your foundation model a big pile of training data that is specific to your domain, and you have the model learn from it.So the model learns to predict missing pieces of data.***

***Like when you say I ice cream, the model predicts that the missing word is eat.Now, this is very similar to how the foundation model is trained.And you are right.***

***The key difference here is that you are fine tuning the model by providing your domain specific dataset.***

***So if you want to train it on your health care data set, you will pass it.The drug structure, scientific studies, all the documents that are related to your drug and the model will learn from it.And it would be able to generate content based on that.***

---
## **supervised fine tuning**

***The next one is what we call as supervised fine tuning, and it's actually a supervised form of learning.Meaning you give detailed labeled training data that has input and output, and the model can learn from it.
So your labeled data set would say something like, how do I find a broken bone bone?And the output would be X-ray.
So you are giving these labeled data sets to your model.And it is learning and improving based on them.***

---

## **reinforcement learning**

**And the last one is what we call as reinforcement learning.And actually reinforcement learning is an old concept.
It's basically a feedback based learning method.***

***So like you give your dog certain instruction and it it follows it.You give it a treat.Over time, the dog realizes that when it would be rewarded and it switches to doing that action.***

***So similarly we will have the model generate some output based on its training.And if it's bad
, we will give it a low score, and if it is good, we will give it a high score.
Over time, the model will learn basis on these high and low score on how to predict the things better.***

---

**So these were the three techniques that we use for fine tuning guys.
Again the generic idea is Llms are pre-trained on large dataset.They perform well in most scenarios.
But if you want a specific pointed results based on your data set, you have a data set of, let's say,healthcare information of your drug, which is not available to GPT because it is your private information and it was never trained on it.**

---

### So now how do you enable GPT to answer that question?

**The answer to that is fine tuning.**

**You will train the model on your data set, and it would be able to give you now answers relevant to that data set.**

***So that's what fine tuning is all about.***

---
### fine tuning is not about.

**Now at the same time, let's talk about what fine tuning is not about.**


- First and foremost, fine tuning is not about creating something from scratch.We are not starting from step zero.

- We are starting from a foundation model that is already trained on a large volume data set, and we 
are only further tweaking it to our specific data set.

- So fine tuning is like building on top of the already existing knowledge it is not replacing that knowledge

**to fine tuning does not mean that you do not need any data.**

- Now you are training a model, right?
You are trying to provide information is specific to your use case, so you will obviously need to provide 
information.You will obviously need to provide data.

- And as with the foundation models or as with any aspect of machine learning that we saw, the better
data that you provide, more accurate and better results you will get.

**Third point there is no universal solution.**

- Each task is different.
- Each data is different.
- Each use case is different.
- So there is no one rule that fits all.
- Your implementation will vary based on your use case and last point.

**Fine tuning is not a magical one time process.**

- It requires iteration.
-It requires architectural changes.
-You can expect multiple cycles of fine tuning before you get into a better shape.

---

Okay, so that was all about fine tuning.

Let's move on.

Let's check out another topic in the next video.

Thank you.